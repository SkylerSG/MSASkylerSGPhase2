{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Summary - Classification:\n",
    "\n",
    "This data is a set of customers for a car company. The company wants to classify customers into predetermined groups (Segmentation) based off of their history, and they want to classify these customers for marketing purposes.\n",
    "\n",
    "Here's a description of all variables and their meaning:\n",
    "\n",
    "ID: ID <br>\n",
    "Gender: 1 for male, 0 for Female<br>\n",
    "Ever_Married: 1 for Yes, 0 for No<br>\n",
    "Age: Age<br>\n",
    "Graduated: 1 for Yes, 0 for No<br>\n",
    "Profession: One-hot encoded, 1 or 0 at end<br>\n",
    "Work_Experience: Numerical<br>\n",
    "Spending_Score: 2 for low, 1 for high, 0 for average<br>\n",
    "Family_Size: Numerical<br>\n",
    "Segmentation: A through D, 0 through 3<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>Profession_Artist</th>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <th>Profession_Executive</th>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <th>Profession_Marketing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>461735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>464347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>465015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>465176</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>464041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>464942</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender  Ever_Married  Age  Graduated  Work_Experience  \\\n",
       "0  462809       1             0   22          0              1.0   \n",
       "1  466315       0             1   67          1              1.0   \n",
       "2  461735       1             1   67          1              0.0   \n",
       "3  461319       1             1   56          0              0.0   \n",
       "4  460156       1             0   32          1              1.0   \n",
       "5  464347       0             0   33          1              1.0   \n",
       "6  465015       0             1   61          1              0.0   \n",
       "7  465176       0             1   55          1              1.0   \n",
       "8  464041       0             0   26          1              1.0   \n",
       "9  464942       1             0   19          0              4.0   \n",
       "\n",
       "   Spending_Score  Family_Size  Var_1  Segmentation  Profession_Artist  \\\n",
       "0               2          4.0      3             3                  0   \n",
       "1               2          1.0      5             1                  0   \n",
       "2               1          2.0      5             1                  0   \n",
       "3               0          2.0      5             2                  1   \n",
       "4               2          3.0      5             2                  0   \n",
       "5               2          3.0      5             3                  0   \n",
       "6               2          3.0      6             3                  0   \n",
       "7               0          4.0      5             2                  1   \n",
       "8               2          3.0      5             0                  0   \n",
       "9               2          4.0      3             3                  0   \n",
       "\n",
       "   Profession_Doctor  Profession_Engineer  Profession_Entertainment  \\\n",
       "0                  0                    0                         0   \n",
       "1                  0                    1                         0   \n",
       "2                  0                    0                         0   \n",
       "3                  0                    0                         0   \n",
       "4                  0                    0                         0   \n",
       "5                  0                    0                         0   \n",
       "6                  0                    1                         0   \n",
       "7                  0                    0                         0   \n",
       "8                  0                    1                         0   \n",
       "9                  0                    0                         0   \n",
       "\n",
       "   Profession_Executive  Profession_Healthcare  Profession_Homemaker  \\\n",
       "0                     0                      1                     0   \n",
       "1                     0                      0                     0   \n",
       "2                     0                      0                     0   \n",
       "3                     0                      0                     0   \n",
       "4                     0                      1                     0   \n",
       "5                     0                      1                     0   \n",
       "6                     0                      0                     0   \n",
       "7                     0                      0                     0   \n",
       "8                     0                      0                     0   \n",
       "9                     0                      1                     0   \n",
       "\n",
       "   Profession_Lawyer  Profession_Marketing  \n",
       "0                  0                     0  \n",
       "1                  0                     0  \n",
       "2                  1                     0  \n",
       "3                  0                     0  \n",
       "4                  0                     0  \n",
       "5                  0                     0  \n",
       "6                  0                     0  \n",
       "7                  0                     0  \n",
       "8                  0                     0  \n",
       "9                  0                     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_te = pd.read_csv(\"datasets_training\\classification_final_toml.csv\", delimiter=',')\n",
    "scores_te = scores_te.drop(\"Unnamed: 0\", axis=1) #Data needed to be dropped, dropped from original file anyway\n",
    "\n",
    "scores_te.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training imports (some may not be used)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset:<br>\n",
    "We split by 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scores_te[\"Segmentation\"]\n",
    "scores_te_2 = scores_te.drop(\"ID\", axis=1)\n",
    "x = scores_te.drop(\"Segmentation\", axis=1)\n",
    "x.head(10)\n",
    "\n",
    "#Train/Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5176294073518379\n",
      "Summary:\n",
      "-------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.50       329\n",
      "           1       0.39      0.38      0.38       320\n",
      "           2       0.55      0.52      0.54       356\n",
      "           3       0.64      0.65      0.64       328\n",
      "\n",
      "    accuracy                           0.52      1333\n",
      "   macro avg       0.52      0.52      0.52      1333\n",
      "weighted avg       0.52      0.52      0.52      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Logistic Regression model - RandomForest proved similar\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Summary:\\n-------------\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#.48 is pretty bad, check data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm Choices/Choice Made:<br>\n",
    "For the classification set, I made the choice of a RandomForestClassifier model. It's clearly the best model for the task, with multiple decision trees and good handling of multiple data types/scaling, as well as the fact that it's not prone to overfitting, or at least in comparison with other models. It also provided the best eval out of any model I tested (there were many). Although it didn't preform as well as I would've liked, it did preform the best. More comments in the summary on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to evalulate the model: <br>\n",
    "TPR - True Positive Rate - the rate that positive cases are identified.<br>\n",
    "FPR - False Positive Rate - Proportion of cases that are falsely identified by the model. <br>\n",
    "F1 Score - F1 Score factors in errors and provides a useful overall accuracy metric, where closer to 1 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 0.625\n",
      "FPR: 0.2967479674796748\n",
      "F1 Score: 0.5170530855373333\n"
     ]
    }
   ],
   "source": [
    "#Eval\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TPR = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1]) #Regular TPR calculation\n",
    "print(\"TPR:\", TPR)\n",
    "FPR = conf_matrix[0, 1] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "print(\"FPR:\", FPR)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:<br>\n",
    "In summary, the classification model was trained through a random forest classifier model, and finally evaluated based on TPR, F1, and FPR. The model did not preform to the standards expected, although it did preform better than a random guess (which is always preferrable) by a considerable amount, according to the F1 score of the model. For the future, a more reasonable approach would be to use one-hot encoding on much of the data, as well as transforming the data into the training set in a more exact manner/classifying variables for OH encoding in a better way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data provided: [-1.80621838e+02 -1.10931917e+00  4.35560652e+01 -2.63490733e+00\n",
      "  7.54058603e-01 -1.84753897e-01  3.10848507e+00  1.04215382e-01\n",
      " -2.96516851e+00 -7.00036727e-01 -3.12218917e-01 -3.09316142e-01\n",
      " -3.71683881e-01  3.49256636e+00 -4.39015297e-01 -1.64208894e-01\n",
      " -2.84785886e-01 -1.90328990e-01]\n",
      "Corresponding prediction's Segmentation: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "new_data_scaled = scaler.transform([[1,0,22,0,1.0,2,4.0,3,0,0,0,0,0,1,0,0,0,0]]) # expects 18\n",
    "new_predictions = model.predict(new_data_scaled)\n",
    "new_predictions_json = json.dumps(new_predictions.tolist())\n",
    "\n",
    "\n",
    "print(\"New data provided:\", new_data_scaled[0])\n",
    "print(\"Corresponding prediction's Segmentation:\", new_predictions[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
