{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Summary - Classification:\n",
    "\n",
    "This data is a set of customers for a car company. The company wants to classify customers into predetermined groups (Segmentation) based off of their history, and they want to classify these customers for marketing purposes.\n",
    "\n",
    "Here's a description of all variables and their meaning:\n",
    "\n",
    "ID: ID <br>\n",
    "Gender: 1 for male, 0 for Female<br>\n",
    "Ever_Married: 1 for Yes, 0 for No<br>\n",
    "Age: Age<br>\n",
    "Graduated: 1 for Yes, 0 for No<br>\n",
    "Profession: One-hot encoded, 1 or 0 at end<br>\n",
    "Work_Experience: Numerical<br>\n",
    "Spending_Score: 2 for low, 1 for high, 0 for average<br>\n",
    "Family_Size: Numerical<br>\n",
    "Segmentation: A through D, 0 through 3<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>Profession_Artist</th>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <th>Profession_Executive</th>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <th>Profession_Marketing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>461735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>460156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>464347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>465015</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>465176</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>464041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>464942</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender  Ever_Married  Age  Graduated  Work_Experience  \\\n",
       "0  462809       1             0   22          0              1.0   \n",
       "1  466315       0             1   67          1              1.0   \n",
       "2  461735       1             1   67          1              0.0   \n",
       "3  461319       1             1   56          0              0.0   \n",
       "4  460156       1             0   32          1              1.0   \n",
       "5  464347       0             0   33          1              1.0   \n",
       "6  465015       0             1   61          1              0.0   \n",
       "7  465176       0             1   55          1              1.0   \n",
       "8  464041       0             0   26          1              1.0   \n",
       "9  464942       1             0   19          0              4.0   \n",
       "\n",
       "   Spending_Score  Family_Size  Var_1  Segmentation  Profession_Artist  \\\n",
       "0               2          4.0      3             3                  0   \n",
       "1               2          1.0      5             1                  0   \n",
       "2               1          2.0      5             1                  0   \n",
       "3               0          2.0      5             2                  1   \n",
       "4               2          3.0      5             2                  0   \n",
       "5               2          3.0      5             3                  0   \n",
       "6               2          3.0      6             3                  0   \n",
       "7               0          4.0      5             2                  1   \n",
       "8               2          3.0      5             0                  0   \n",
       "9               2          4.0      3             3                  0   \n",
       "\n",
       "   Profession_Doctor  Profession_Engineer  Profession_Entertainment  \\\n",
       "0                  0                    0                         0   \n",
       "1                  0                    1                         0   \n",
       "2                  0                    0                         0   \n",
       "3                  0                    0                         0   \n",
       "4                  0                    0                         0   \n",
       "5                  0                    0                         0   \n",
       "6                  0                    1                         0   \n",
       "7                  0                    0                         0   \n",
       "8                  0                    1                         0   \n",
       "9                  0                    0                         0   \n",
       "\n",
       "   Profession_Executive  Profession_Healthcare  Profession_Homemaker  \\\n",
       "0                     0                      1                     0   \n",
       "1                     0                      0                     0   \n",
       "2                     0                      0                     0   \n",
       "3                     0                      0                     0   \n",
       "4                     0                      1                     0   \n",
       "5                     0                      1                     0   \n",
       "6                     0                      0                     0   \n",
       "7                     0                      0                     0   \n",
       "8                     0                      0                     0   \n",
       "9                     0                      1                     0   \n",
       "\n",
       "   Profession_Lawyer  Profession_Marketing  \n",
       "0                  0                     0  \n",
       "1                  0                     0  \n",
       "2                  1                     0  \n",
       "3                  0                     0  \n",
       "4                  0                     0  \n",
       "5                  0                     0  \n",
       "6                  0                     0  \n",
       "7                  0                     0  \n",
       "8                  0                     0  \n",
       "9                  0                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_te = pd.read_csv(\"datasets_training\\classification_final_toml.csv\", delimiter=',')\n",
    "scores_te = scores_te.drop(\"Unnamed: 0\", axis=1) #Data needed to be dropped, dropped from original file anyway\n",
    "\n",
    "scores_te.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training imports (some may not be used)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scores_te[\"Segmentation\"]\n",
    "scores_te_2 = scores_te.drop(\"ID\", axis=1)\n",
    "x = scores_te.drop(\"Segmentation\", axis=1)\n",
    "x.head(10)\n",
    "\n",
    "#Train/Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5378844711177795\n",
      "Summary:\n",
      "-------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.48      0.47       316\n",
      "           1       0.45      0.41      0.43       315\n",
      "           2       0.56      0.55      0.56       328\n",
      "           3       0.66      0.68      0.67       374\n",
      "\n",
      "    accuracy                           0.54      1333\n",
      "   macro avg       0.53      0.53      0.53      1333\n",
      "weighted avg       0.54      0.54      0.54      1333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Logistic Regression model - RandomForest proved similar\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Summary:\\n-------------\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#.48 is pretty bad, check data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm Choices/Choice Made:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to evalulate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR: 0.6482412060301508\n",
      "FPR: 0.3076923076923077\n",
      "F1 Score: 0.5370463610888705\n"
     ]
    }
   ],
   "source": [
    "#Eval\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TPR = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1]) #Regular TPR calculation\n",
    "print(\"TPR:\", TPR)\n",
    "FPR = conf_matrix[0, 1] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "print(\"FPR:\", FPR)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 13 features, but StandardScaler is expecting 18 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m new_data_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform([[\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m3.0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m93\u001b[39;49m,\u001b[39m91\u001b[39;49m]])\n\u001b[0;32m      3\u001b[0m new_predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(new_data_scaled)\n\u001b[0;32m      4\u001b[0m new_predictions_json \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(new_predictions\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[1;32mc:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    989\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    991\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m--> 992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    993\u001b[0m     X,\n\u001b[0;32m    994\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    995\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    996\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    997\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    998\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    999\u001b[0m )\n\u001b[0;32m   1001\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1002\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\skyso\\Documents\\GitHub\\MSASkylerSGPhase2\\venv\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 13 features, but StandardScaler is expecting 18 features as input."
     ]
    }
   ],
   "source": [
    "import json\n",
    "new_data_scaled = scaler.transform([[0,1,3,1,1,2,2,1,3.0,1,2,93,91]])\n",
    "new_predictions = model.predict(new_data_scaled)\n",
    "new_predictions_json = json.dumps(new_predictions.tolist())\n",
    "\n",
    "\n",
    "print(\"New data provided:\", new_data_scaled[0])\n",
    "print(\"Corresponding prediction's math score:\", new_predictions[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
